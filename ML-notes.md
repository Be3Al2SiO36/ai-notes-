<!-- ---
id: QA-000000
title: "G検定の出題範囲"
question: 
  - "ディープラーニングとは何ですか？"
  - "機械学習とは何ですか？"
  - "深層学習とか何ですか？"
category: "人工知能"
audience: "internal"
tags:
  - "特徴"
  - "学習"
updated_date: "2025-06-30"
status: "公開中"
--- -->

# ディープラーニングについて

## 1. 人工知能とは
### 1-1. 人工知能の定義
#### 1-1-1. 人工知能とは
* 人工知能とは「推論、認識、判断など人間と同様な知的処理能力を持つ情報処理システム」である。
「知的な、知能」の定義が定まっていないため、「人工知能とは何か？」の解釈は多岐にわたる。
「人間と同様な知的処理能力」を実現するために、何が必要なのか。人間と同様に右脳・左脳の機能を実現する必要があるのか。
また、感情・こころ・価値観・人格なども必要な要素なのか。（それらの定義もままならない状況なのに）

AI（Artificial Intelligence）は、**人間のような知的活動を模倣する技術**の総称です。

* 人工知能とは、コンピュータ制御された機械が人間と同様の知能を示す行動を実現する技術。またその研究分野を指す。
具体的には、学習、推論、問題解決、知覚、言語理解などを機械に実装しようとする試みで、ざっくり2つのタイプに分類される。

1. 汎用人工知能（AGI、Strong AI）：人間と同等以上の知能を持ち、自律的に思慮し、理解し、学ぶことができる人工知能。
現在実現されていない。
2. 応用人工知能（ANI、Weak AI）：特定のタスクを実行するために設計された人工知能。
音声認識、画像認識、自動運転、検索エンジン（Geminiとかも）

### 機能・目的による分類（最も基本）

| 分類名 | 説明 | 例 |
|--------|------|----|
| **特化型AI（ANI）** | 特定のタスクに特化したAI。現在のAIのほとんどがこれ。 | 音声認識、画像分類、ChatGPTなど |
| **汎用AI（AGI）** | 人間のように幅広い知的活動ができるAI。まだ実現されていない。 | 未来のAI像 |
| **超知能AI（ASI）** | 人間の知能を超えるAI。倫理的・哲学的議論の対象。 | SFの世界（例：映画『HER』） |

### 技術レベルによる分類

| 分類 | 説明 |
|------|------|
| **ルールベースAI** | if文などの手続き型。明示的なルールに従う |
| **機械学習（ML）** | データからパターンを学習し、予測や分類を行う |
| **深層学習（DL）** | ニューラルネットワークを用いた機械学習の一種。特徴量も自動で学習 |

### 知能の強さによる分類

| 分類 | 別名 | 説明 |
|------|------|------|
| **弱いAI（Weak AI）** | 特化型AI | 限定されたタスクに特化。現在のAIはほぼこれ |
| **強いAI（Strong AI）** | 汎用AI | 自律的に思考・学習・判断できるAI（未実現） |

人間と同様の行動を実現するために、さまざまな技術、手法が使われる。
その技術のひとつが機械学習であり、機械学習とは大量のデータの法則性やルールを見つけて学習し、分類・予測する技術である。
機械学習のなかでも、深層学習（ディープラーニング）は人間の脳神経回路を模した多層ニューラルネットワークを用いて、
大量のデータから自動的に特徴を抽出し学習する機械学習の1手法。従来の機械学習では人間が特徴量を定義する必要があったが、
深層学習ではデータから自動的に特徴を学習できるため、画像認識や音声認識、自然言語処理などより複雑な処理の精度が高まる。

**特徴量とは**
モデルが学習や予測を行う際に必要なデータの特徴を数値化したもの（売上予測なら、実績、価格、曜日、気温など）

**モデルとは**
機械学習のプロセス自体のアルゴリズムそのものでもないし、プログラムのことでもない。訓練データからパターンや関係性を学習し、入力に対して予測や判断をする数理的な仕組みのこと。アルゴリズムは「学習の方法」、モデルは「学習の結果できた成果物」
学習された入力データと出力データの関係性を表現する数学的な関数や構造を指す。数式や重み（パラメータ）のかたちで保存され、推論（予測）に利用される。

Geminiもモデル。Googleが開発した大規模言語モデルの一種。
つまり、Geminiは「質問に答える」「文章を生成する」「翻訳する」「要約する」「コンテンツ作成」などのユーザー支援を目的とし、Googleが設計した深層学習アルゴリズム（特にTransformerアーキテクチャ）を用いて、膨大なテキストデータとコードデータから学習して構築された大規模な「知識」や「パターン」の集合体 ＝ モデル
もちろん、このモデルを動かすためのプログラムは当然存在するが、そのプログラム自体が「Gemini」という名前ではない。

**機械学習のプロセス自体のアルゴリズムとは**
モデルを学習させるための手法。線形回帰や決定木ニューラルネットワークなど。

┌──────人工知能──────┐
│　　　　　　　　　　 │ 
│ ┌───機械学習───┐   │
│ │　　　　　　　 │   │
│ │ ┌─深層学習─┐ │   │
│ │ │   ★★   │ │   │
└─└─└─────────┘─┘───┘

#### 1-1-2. 人工知能の大まかな分類
人工知能を「周囲の状況（入力）によって自動的に振る舞い（出力）を変えるエージェント（プログラム）」という視点から、人工知能を4つのレベルに分類する。ここでの「エージェント」は、単なるプログラムではなく、自律性（自分で判断）、反応性（環境に応じて変化）、目的志向性（目的を持って行動）をもつ存在として捉えてるよ。

* レベル1：単純な制御プログラム
エアコンの温度調整や、洗濯機の水量調整。これらはすべての振る舞いがあらかじめ決められていて、その通りに動くだけ。
制御工学やシステム工学の分野で長年培われてきた技術。

* レベル2：古典的な人工知能
お掃除ロボットや診断プログラム。探索・推論・知識データを利用することで、極めて複雑な振る舞いをする。
深層学習につながる人工知能の研究もこのレベルのものを人工知能として研究することから始まっている。
現代の機械学習ベースのAIとは異なる、ルールベースと呼ばれるアプローチの典型例。

* レベル3：機械学習を取り入れた人工知能
検索エンジンや交通渋滞予測など、非常に多くのサンプルデータをもとに入力と出力の関係を学習したもの。パターン認識という古くからの研究をベースに発展し、2000年代ビックデータ時代を迎えて、さらに進化している。機械学習では、どのような特徴が学習結果に大きく影響するか（特徴量）を知ることがとても重要。特徴量がわかっていると効率的に学習できる。

* レベル4：深層学習を取り入れた人工知能
画像認識、音声認識、自動翻訳など。深層学習は特徴量を自動的に学習する技術。

> 「エージェントアプローチ人工知能」共立出版

#### 1-1-3. AI効果
AI効果とは、人工知能で何か新しいことが実現され、その原理が分かってしまうと「それは単純な自動化であって知能とは関係ない」と結論付けてしまう人間の心理。クソだね。
人間特有の知能であると思っていたものが機械にも実現できてしまうと、「そんなわけはない」と思いがちで、時代とともに人工知能のイメージが変化する理由のひとつ。

#### 1-1-4. 人工知能とロボットの違い
ロボットの脳にあたる部分が人工知能だが、人工知能の研究とは、ロボットの脳だけを対象としておらず、「考える（知的処理能力）という目に見えないもの」を中心に取り扱う学問。



### 1-2. 人工知能研究の歴史
#### 1-2-1. 歴史
* 1946年：汎用コンピュータ、エニアックの誕生（いずれコンピュータが人間を凌駕するやろな…）
* 1956年：ダートマス会議におて人工知能という言葉が初めて使われた（知的に行動したり、思考したりするコンピュータプログラムって実現可能かな…）
  これまで四則演算など数値計算しかできなかったところに数学の定理を自動的に証明したり。

* 第1次AIブーム
探索・推論の時代：1950年代後半～1960年代
「探索」や「推論」の研究が進み、特定の問題に対して解が提示できる。（一回盛り上がる）
迷路や数学の定理の証明のような簡単な問題（トイ・プログラム）は解けても、複雑な現実世界の問題は解けない。（落胆され、1979年代冬の時代に突入）

* 第2次AIブーム
知識の時代：1980年代
コンピュータに「知識」を入れると賢くなるぞアプローチで、データベースに大量の専門知識をため込んだ「エキスパートシステム」と呼ばれるシステムが作られた。（また盛り上がる）
やってみたものの、知識の蓄積・管理の困難さに直面。（もう無理、1995年ごろから再び冬の時代へ）
現実世界は例外だらけで、曖昧だらけ。

* 第3次AIブーム
機械学習・特徴表現学習の時代：2010年代
ルールベースAIが直面した限界を超えるアプローチとして、
人工知能が自ら知識を獲得する機械学習が実用化される。（時は大量ビックデータ時代）

自然言語処理の分野において、これまではルールベース・統計ベースの手法が主流だったため長文になると破綻したり、自然な文章がうまく作れなかった。そこに登場したのが深層学習（特にGoogleのTransformer）。深層学習を駆使して「人間が書いたような自然な文章が作れるようになった。（第4次ブーム来たか…？）

機械学習 ⊇ 深層学習 ⊇ 特徴表現学習 

- **機械学習**の目的は、未知のデータに対して正しく予測・分類すること。そのために、過去のデータからパターンを学ぶ＝うまく予測できるルールを見つける。
「うまく予測できるルールってなに？どうやってルールを見つけるの？」過去のたくさんの入力と過去データの中にある正解を比較して、「この特徴がこの結果に強く関係してそう」と重み付けする。その重みの組み合わせ＝ルール。このルールを使って、未知のデータに対応するよ。
人間が明示的にプログラミングするのではなく、学んだルールを使って予測することが目的。
あ、学習は自動だけど、手動・自動生成された特徴を使うよ。

- **深層学習**は、機械学習のなかでも自動で特徴量を見つけるための最強クラスの技術。「特徴表現学習」に特化している。で、人間のように目利きして、判断する。写真の写っているものを自動で認識したり、音声を正確に文字起こししたり、自然な会話を自動生成したり。

- **特徴表現学習**は、予測に効くルールを見つけやすくなるように、データから有用な特徴量（表現）を自動的に見つける方法。特徴表現学習は、「特徴の候補を作る → 予測に使ってみる → 結果が良ければOK、悪ければ改善 → また次！」を自動で繰り返している。深層学習の中核的な能力。特徴表現学習は深層学習以外でも可能だけど、深層学習が最も強力な手法として使われている。

- **「深層学習」と「特徴表現学習」**は密接に絡み合っていて、どちらが「手段」でどちらが「目的」なのかが曖昧になりがち。深層学習は特徴表現学習を行うための手法のひとつ
- 深層学習 = 手段（方法）
- 特徴表現学習 = 目的（何をしたいか）

##### 機械学習（Machine Learning）とは？

- **定義：** データからパターンやルールを学習し、予測や分類を行う技術
- **特徴：**
  - 人間が「特徴量（予測に使う指標）」を設計する必要がある
  - 比較的少ないデータでも学習可能
  - アルゴリズム例：決定木、SVM、ランダムフォレスト、線形回帰など
- **活用例：**
  - スパムメール判定
  - 売上予測
  - 顧客の離脱予測

##### 深層学習（Deep Learning）とは？

- **定義：** 機械学習の一種で、**多層のニューラルネットワーク**を用いて特徴量も自動で学習する手法
- **特徴：**
  - 特徴量の設計を人間がしなくてもよい（自動抽出）
  - 大量のデータと高い計算資源（GPUなど）が必要
  - アーキテクチャ例：CNN（画像）、RNN（時系列）、Transformer（自然言語）
- **活用例：**
  - 顔認識・画像分類
  - 音声認識・自動翻訳
  - 生成AI（ChatGPT、画像生成など）

##### 機械学習と深層学習
**機械学習と深層学習　比較表**

| 観点             | 機械学習（ML）                     | 深層学習（DL）                            |
|------------------|----------------------------------|------------------------------------------|
| 特徴量の設計     | 人間が設計（手動）                  | モデルが自動で抽出                         |
| モデルの構造     | 比較的シンプル（決定木など）         | 多層のニューラルネットワーク                |
| データ量の必要性  | 少なくてもOK                       | 大量のデータが必要                         |
|計算資源の必要性   |そこまで高くない（CPUでも可）        |GPUなどハイパワーな環境が必要になることが多い |
| 処理対象         | 表形式などの構造化データに強い       | 画像・音声・自然言語など非構造データに強い   |
| 解釈性           | 比較的高い（ホワイトボックス）       | 低い（ブラックボックスになりやすい）         |


- **機械学習：**「猫の特徴は耳が尖ってるよ」と人間が教える
- **深層学習：**「これが猫だよ」とだけ教えて、AIが自分で耳の形などを見つけて学ぶ

機械学習と深層学習は、**目的やデータの性質によって使い分ける**のがポイントだよ！

**AI技術の階層構造**
人工知能（AI）
├─ ルールベースAI（if文などの手続き型）
└─ 学習型AI（←ここが進化の本丸！）
    └─ 機械学習（ML）
        ├─ 教師あり学習（分類・回帰）
        ├─ 教師なし学習（クラスタリングなど）
        ├─ 強化学習（行動と報酬で学ぶ）
        └─ 深層学習（DL）
            ├─ 特徴表現学習（特徴を自動抽出）
            └─ Transformer（NLPや画像で大活躍）
                ├─ BERT（意味理解）
                ├─ GPT（文章生成）
                └─ マルチモーダルモデル（画像×言語）
    └─ 生成AI（Generative AI）
        ├─ 画像生成（例：DALL·Eなど）
        ├─ 音声生成（TTS、声まねなど）
        └─ 文章生成（NLP＋言語生成）

**自然言語処理（NLP）は「AI×言葉」の技術領域全体で、その中の最新鋭が深層学習ベースのGPTやBERTだよ！**



### 1-3. 人工知能分野の問題

#### 1-3-1. トイ・プロブレム（おもちゃの問題）
現実世界の問題をコンピュータで解決しようとするのは、問題が複雑すぎて取り扱うのが難しい。そこで、コンピュータで扱えるように、本質を損なわない程度に問題を簡略化する。これがトイ・プロブレム。
第1次AIブームの時代は、数学の定理の証明や、迷路・パズル、チェス・将棋など非常に限定された状況で設定された"おもちゃの"問題であり、人工知能ではそんな問題しか解けないと明らかになった。

#### 1-3-2. フレーム問題
いまだ解決されていない人工知能研究の最大の問題。AIが現実世界で行動するには、無数の事実の中から関連するものだけを選び出す必要がある。しかし、何が「関係あるか」を判断するのは非常に難しい。結果として、効率的な推論や意思決定が困難になる。
これは人間にも起こりうるけど。

#### 1-3-3. チューリングテスト
人工知能ができたかどうかを判断する方法。
別の場所にいる人間がコンピュータと会話し、相手がコンピュータだと見抜けなかったらコンピュータに知能があるね！てこと。

#### 1-3-4. 強いAIと弱いAI
強いAIは、「人間の心や脳の働きは情報処理」という考えのもと、「本物の心をもつ人工知能は実現可能」という立場。本物の心ってなんだろうね。
弱いAIは、コンピュータは人間の心を模倣するだけで本物の心を持つことはできない。人間の知的活動と同じような（限定された）問題解決ができる便利な道具であればいい」という立場。
「中国語の部屋」という思考実験があり、心がどこに存在するのか。意味はどこにあるのか。コンピュータは記号操作を行っているだけなので、そこに心も意味も意思もないんじゃないの？というジョン・サールさんの主張。

#### 1-3-5. シンボルグラウンディング問題（記号接地問題）
記号（シンボル）と対象がいかにして結びつくかという問題。
コンピュータは記号の意味がわかっていないので、記号が意味するものと結び付けられない。
現代の深層学習AI（特に大規模言語モデルなど）は、この問題を完全に解決したわけではないけど、疑似的・部分的に解決に近づいている。
「りんご」という単語を学習する時、「果物」「甘い」「木」などの他の単語、りんご画像、文章で「りんご」の使われ方を一緒に学習して、その結果、「りんご」という記号がどのような概念や知覚情報と結びついているのかを統計的なパターンとして認識するよ。これで、あたかも「りんご」の意味を理解しているような振る舞いをするようになってる。

#### 1-3-6. 身体性
知能が成立するためには、身体が不可欠であるという考え方。外界と相互作用できる身体がないと概念はとらえきれないというのが身体性というアプローチ。

#### 1-3-7. 知識獲得のボトルネック
人間がもっている一般常識は膨大なので、たったひとつの文章を翻訳するにもその膨大な一般常識を取り扱う必要があり、それら膨大な知識を取り扱うのは困難で、コンピュータが知識を獲得することの難しさを「知識獲得のボトルネック」という。1970年代後半はルールベース機械翻訳が一般的で、1990年以降は統計的機械翻訳が主流となり性能は飛躍的に向上した。機械翻訳の難しいところは、コンピュータが意味を理解していないこと。統計的機械翻訳もまだ実用レベルではなかった。2010年代からニューラル機械翻訳という深層学習を応用した機械翻訳が登場。

<!-- tag: AI定義・章1 -->
**【復習ポイント】第1章：人工知能とは**
人工知能の定義と分類
- 人工知能とは、人間のような知的処理（推論・認識・判断など）を行う情報処理システム。
- 「知能」の定義が曖昧なため、AIの定義も多様。
- AIは「人間の知的活動を模倣する技術」の総称。

**分類（機能・目的別）**
| 分類 | 説明 | 例 | 
| 特化型AI（ANI） | 特定のタスクに特化 | 音声認識、画像分類、ChatGPT | 
| 汎用AI（AGI） | 人間のような知能 | 未来のAI像（未実現） | 
| 超知能AI（ASI） | 人間を超える知能 | SFの世界（例：映画『HER』） | 

**分類（技術レベル別）**
- ルールベースAI：if文などの手続き型
- 機械学習（ML）：データからパターンを学習
- 深層学習（DL）：特徴量も自動で学習するMLの一種

**分類（知能の強さ別）**
| 分類 | 別名 | 説明 | 
| 弱いAI | 特化型AI | 限定されたタスクに特化（現在のAI） | 
| 強いAI | 汎用AI | 自律的に思考・学習・判断できる（未実現） | 

**機械学習・深層学習・特徴表現学習の関係**
- 機械学習 ⊇ 深層学習 ⊇ 特徴表現学習
- 機械学習：人間が特徴量を設計
- 深層学習：特徴量を自動抽出（CNN, RNN, Transformer）
- 特徴表現学習：予測に有効な特徴を自動で見つけるプロセス

**モデルとアルゴリズムの違い**
- モデル：学習の成果物。入力と出力の関係性を表す数学的構造。
- アルゴリズム：モデルを学習させる手法（例：線形回帰、決定木、ニューラルネットワーク）

**人工知能の4つのレベル（エージェント視点）**
| レベル | 内容 | 例 | 
| レベル1 | 単純制御 | エアコン、洗濯機 | 
| レベル2 | 古典的AI | お掃除ロボット、診断プログラム | 
| レベル3 | 機械学習型AI | 検索エンジン、交通予測 | 
| レベル4 | 深層学習型AI | 画像認識、音声認識、翻訳 | 

**人工知能研究の歴史**
| 時代 | 内容 | 課題 | 
| 第1次AIブーム | 探索・推論 | 現実問題に弱い | 
| 第2次AIブーム | 知識ベース | 知識管理が困難 | 
| 第3次AIブーム | 機械学習 | ビッグデータで進化 | 
| 第4次AIブーム？ | 深層学習（Transformer） | 自然な文章生成が可能に | 

**人工知能分野の重要な問題**
| 問題名 | 内容 | 
| トイ・プロブレム | 問題を簡略化して扱う手法。現実には不十分。 | 
| フレーム問題 | 何が変化し、何が変化しないかを判断するのが難しい | 
| チューリングテスト | AIが人間と見分けがつかないかどうかの判定法 | 
| 強いAIと弱いAI | 心を持つかどうかの哲学的立場の違い | 
| シンボルグラウンディング問題 | 記号と意味の結びつきが困難 | 
| 身体性 | 知能には身体と環境との相互作用が不可欠 | 
| 知識獲得のボトルネック | 膨大な常識をAIが獲得するのが困難 | 


## 2. 人工知能をめぐる動向
### 2-1. 探索・推論
第1次AIブームで中心的な役割を果たした「探索・推論」について。一部は現在も研究され続けている。

#### 2-1-1. 迷路（探索木）
まず、迷路を画像ではなく、扱いやすいデータ構造に変換する。迷路の分岐点や行き止まりをノード（点）、通路をエッジ（線）とするグラフという考え方で表現する。スタート地点・ゴール地点もそれぞれノードになる。"スタートノードからゴールノードまでの経路を見つける問題"に置き換える。
木のような構造をしているので、探索木と呼ばれているよ。

つまり、探索木は場合分けで、場合分けを続けていたら、いつか目的の条件に合うものが出現するという考え方をベースにしている。

代表的な探索アルゴリズム
**深さ優先探索（DFS：Depth-First Search）**
あるノードからとにかく行けるところまで行って、行き止まりになったら1つ手前のノードまで戻る
- 実装が簡単
- 結果を出すまでの探索プロセスが短時間で済む可能性がある
- 結果（経路）が、距離的に一番短いとは限らない

とりあえず答えを一つ、素早く見つけたい場合に有効な手法。そして、運が良ければ最短にもなるし、運が悪ければ全て網羅するまで見つからないこともあるよ。

**幅優先探索（Breadth-First Seaarch）**
スタート地点から近い順に水平方向で全方向を均等に探索していく。スタート地点から1つ進める全ノードを調べ、次に2つ進めるノード全ての点を…。
- 最初に見つかったゴール地点までの経路が必ず最短経路になる
- 全ての可能性を同時に調べるため、迷路が広くなると計算量・メモリ消費量が非常に大きくなる。

スタート地点からゴールまでの「最短経路」や「最小手数」を確実に見つけたい場合に有効な手法。

**「最適な答えが絶対に必要か？」**という点が、どちらのアルゴリズムを選択するかの大きな判断基準だよ。

**A*（エースター）アルゴリズム**
深さ優先、幅優先のいいとこどりアルゴリズム。カーナビとかでも実際に使われてるよ。
"次にどの地点を調べるべきか"を**評価値**というスコアを計算して決定。評価値が最も低い地点を優先的に探索。
評価値 = スタートからの実コスト（スタート地点から現地点までのコスト = 距離） + ゴールまでの推定コスト（現地点からゴールまでどれくらいかかりそうかという予測コスト）
f(n)=g(n)+h(n)

推定コストは未来に対するヒューリスティック（経験則に基づいた推測）。ヒューリスティックは、人間がプログラミングの段階で事前に定義した、単純で計算が速い「経験則」や「近道」のルールです。そこには機械学習は介在しないよ。

A*アルゴリズムの例で言えば、ヒューリスティック関数 h(n) は「ゴールまでの直線距離」などが使われます。

- 誰がルールを作るか？: 人間（プログラマー）。
- どうやって作るか？: 「ゴールに近づけばコストが下がるはずだ」という論理的な推測に基づき、「2点間の直線距離を計算する」という単純な計算式を直接プログラムに書き込みます。
- データは必要か？: 不要です。必要なのは、現在地とゴールの座標だけです。

要するに、ヒューリスティックは人間が与えた「だいたいこっちの方角が良さそうだ」というシンプルな道しるべです。

また、A*アルゴリズム自体は、与えられたコストを元に計算する古典的なアルゴリズムです。しかし、その入力データである「コスト（所要時間）」を機械学習によって高精度化することで、アルゴリズム全体の性能が劇的に向上し、現実世界の複雑な交通状況に対応できるようになる。

### 2-1-2. ハノイの塔
これもまずはコンピュータが扱いやすいデータ構造に変換する。コンピュータは主に**「再帰（さいき）」**という考え方を使ってハノイの塔を解きます。これは、大きな問題を、それより小さな同じ形の問題に分解して解いていく手法。
コンピュータは「n枚の移動」を「n-1枚の移動」と「1枚の移動」に分解する処理を、円盤が1枚になるまで繰り返します。

### 2-1-3. ロボットの行動計画（プランニング）
STRIPS（Stanford Research Institute Problem Solver）やPDDL (Planning Domain Definition Language) といった記述形式で体系化されている。
行動計画の3つの主要な要素
1. 初期状態（initial State）：世界の"今"の状態
2. ゴール状態（Goal State）：達成したい"目標"の状態
3. 行動の定義（Action Definitions）：ロボットが実行可能な"行動リスト"
- 行動：行動の名前
- 前提条件：その行動を実行するために満たされてるべき条件
- 結果：その行動を実行した後に世界がどう変化するか

### 2-1-4.ボードゲーム（オセロ・チェス・将棋・囲碁）
ボードゲームをコンピュータで解く基本は探索だけど、事実上すべての組み合わせは天文学数字になって、探索しきれない。組み合わせ爆発。そこで、効率よく探索するために、"コスト"の概念を取り入れる。あらかじめわかっている知識や経験を利用してコストを計算すれば探索を短縮できる。ここで利用する知識をヒューリスティック知識と呼ぶ。
ボードゲームはパズルと違い相手がいるので、自分が指した後に相手が指し、また自分が指して相手が指すを繰り返す探索木を作らないといけない。

**Mini-Max法**
自分の番で自分が有利（自分のスコアが最大）に指すべき。相手の番では相手が有利（自分のスコアが最小）になるよう相手は指すはず。これを前提に先読みをする戦略。

**αβ法**
Mini-Max法の探索を効率化するための最適化手法。明らかに損、とわかる手を"途中で評価をやめる（枝刈りする）"ことで計算量を大幅削減。**「これ以上探索しても無駄な手」**を早期に見抜くコツは、「α >= β」 となった瞬間、その先の探索はばっさり打ち切る。
- アルファ値 (α): 自分（Max）が、現時点で保証できる最も高いスコア
- ベータ値 (β): 相手（Min）が、現時点で許してくれる最も低いスコア

自分の局面で、探索する必要のない相手の手の評価をやめることをαカット。相手の局面で探索する必要のない自分の手の評価をやめることをβカット。

### 2-1-5. モンテカルロ法
数学的に直接計算するのが難しい問題でも、「たくさん試行すれば、だいたいこんな感じになるだろう」と力技で答えの傾向を探る。
囲碁クラス（19路盤で10の360乗通り）のボードゲームだと、どんなに効率よく探索しても全ての手を読み切ることができない。特に序盤。
探索しなければならない組み合わせが多すぎるだけでなく、ゲーム盤のスコア（コスト評価）に問題があることが分かってきた。
モンテカルロ法では、ゲームがある局面まで進んだらあらかじめ決められた方法でゲームの局面のスコアを評価するという方法を完全に破棄する。その代わり、どのようにスコアを評価するか、コンピュータが2人の仮想プレーヤーを演じて、完全にランダムに指し続ける方法でシミュレーションし、とにかく終局（プレイアウト）させる。ゲーム後半は指せる場所が限定されるので、数多く指して最良のものを選ぶという評価方法が優れていることがわかったんだよ。

「AlphaGo」はモンテカルロ木探索（論理的計算能力）と深層学習（パターン認識能力）を融合させたよ。

「深層学習 ＋ モンテカルロ木探索」の最強タッグで、人間のような「直感」と、コンピュータならではの超人的な「計算力」を両立させることができました。
- ポリシーネットワーク (Policy Network) 
これは**「プロ棋士の直感」**のような役割を果たします。
何をするか？: 現在の盤面を見て、「次に打つべき有望な手は、この3〜4箇所だろう」と、候補手を瞬時に絞り込みます。
効果: 囲碁の膨大な選択肢の中から、明らかに悪そうな手を除外し、有望な手だけをモンテカルロ木探索に渡します。これにより、探索の効率が劇的に向上します。

- バリューネットワーク (Value Network) 
これは**「大局観」や「形勢判断」**の役割を果たします。
何をするか？: 現在の盤面を見て、「この局面は、黒が70%くらいの確率で勝てそうだ」と、どちらがどれくらい有利かを数値で評価します。
効果: モンテカルロ木探索では、通常ゲームの最後までシミュレーションしますが、途中でこのバリューネットワークを使うことで、最後までシミュレーションしなくても、その局面の良し悪しを正確に判断できます。これにより、探索時間を大幅に短縮できます。

1. まずポリシーネットワークが「この辺りが良さそうだ」と有望な手を教える。
2. モンテカルロ木探索が、その有望な手に絞って先読みを開始する。
3. ある程度先読みを進めたら、バリューネットワークが「その局面は有利だよ」と評価を下す。
4. この「直感」と「形勢判断」を頼りに、モンテカルロ木探索は非常に効率よく、かつ深く、最善手を探し当てることができる。

### 2-2. 知識表現
第2次AIブームで中心的役割を果たした知識表現の研究とエキスパートシステムについて

### 2-2-1. 人工無能
特定のルール・手順に沿って会話を機械的に処理するだけで、実際は会話の内容を理解しているわけではない = 人工無能
元祖人工無能「イライザ」はあらかじめ用意されたパターンに応じた発言を返答する仕組みになっている。その返答が自然なので、人間と対話しているような錯覚（イライザ効果）に陥る。でも、イライザはオウム返しをしているだけなので、相手の発言を理解しているわけではない。機械的に生成された言葉でも、そこに知性があるように反応してしまう人間心理の不思議。コンピュータに意思決定を任せることは危険性がある。

### 2-2-2. 知識ベースの構築とエキスパートシステム
専門分野の知識を取り込み、その分野の専門家のように振る舞うプログラムをエキスパートシステムと呼ぶ。
初期エキスパートシステムで影響力大だったのが、マイシン（血液中のバクテリアに診断支援をするルールベースのプラグラム）

### 2-2-3. 知識獲得のボトルネック（エキスパートシステムの限界）
知識ベースを構築するには、専門家、ドキュメント、事例などから知識を獲得する必要があります。ドキュメントや事例から知識を獲得するには自然言語処理や機械学習という技術を利用できるが、最大の知識源の人間の専門家からの知識獲得は困難。専門家の知識の多くは経験的なもので、知識が豊富であればあるほど暗黙知であるため、自発的に述べてもらうのは不可能。うまくヒアリングして取り出す必要がある。
知識ベースの構築で、獲得した知識が増えると一貫していないものが出てくるので、保守が非常に困難。

専門家の持つ高度な知識は明示的で体系化されている場合が多いが、常識的な知識は暗黙知で明文化されていないことが多い。明文化されていない知識をコンピュータで扱うのはとても難しいし、知識を共有したり再利用したりする方法もポイントになってきた。こうした問題を解決するために、コンピュータで知識を取り扱う方法論が注目され、意味ネットワークやオントロジーの研究が活性化する。

### 2-2-4. 意味ネットワーク
もともとは認知心理学における長期記憶の構造モデルとして考案された。現在では、人工知能においても重要な知識表現のひとつとなっている。
"概念"をラベルの付いたノードで表現し、概念間の関係をラベルの付いたリンクで結んだネットワークとして表す。人間の知識をコンピュータに分かりやすく伝えるために使われるよ。
**is-a（～は～である）**：継承関係で、矢印の向いている側が上位概念、矢印の始点が下位概念　[犬] --(is-a)--> [動物]
**part-of（～は～の一部である）**：属性を表している。[肉球] --(part-of)--> [足]
**has-a（～は～を持っている）**：[動物] --(has-a)--> [心臓]
他は、**name**や、**number**など。

自然言語処理 (NLP)、人工知能 (AI) の推論、情報検索とデータ管理などの分野で利用される。

### 2-2-5. オントロジー（概念体系を記述するための方法論）
- Cycプロジェクト
エキスパートシステムが柔軟な能力を発揮し、人間のように柔軟は知的能力を実現するには広範囲に及ぶ常識が必要で、この課題に挑戦するためにすべての一般常識をコンピュータに取り込もうとするcycプロジェクトが1984年スタートし、びっくりだけど現在も継続している。
- オントロジー（概念化の明示的な仕様）
知識を記述したり共有することが難しいことがわかってくると、知識を体系化する方法論が研究され始める。Cycプロジェクトは開発と保守にコストがかかるという問題に端を発して、知識の共有と再利用に貢献する学問としての知識工学が期待されるようになる。
本来は哲学用語で存在論（存在に関する体系的理論）という意味。
知識を記述する時に用いる「言葉（語彙）」や「その意味」、「それらの関係性」を他人とも共有できるように明確な仕様として定義しておく。
その記述には主にRDF、RDFS、OWLといった標準的な言語が使われ、コンピュータが解釈しやすいように、知識を「主語-述語-目的語」の形式で記述していくのが基本だよ。

**RDF (Resource Description Framework)**
オントロジーの最も基本的な骨格で、あらゆる情報をトリプル（3つ組）で表現する
- 基本形: [主語] - [述語] -> [目的語]
- 例: [東京] - [は] -> [日本の首都]
しかし、RDFだけでは「首都」とは何か、「東京」が「都市」の一種であることなどは分からない。

**RDFS (RDF Schema)**
RDFで使われる語彙（クラスやプロパティ）を定義し、基本的な階層関係を追加する
- クラスの定義: [首都] は [都市] の一種である (rdfs:subClassOf)
- プロパティの定義: [isCapitalOf] は [場所] と [国] を結びつける (rdfs:domain, rdfs:range)
これにより、「東京は都市である」といった推論が可能になる。

**OWL (Web Ontology Language)**
OWLは、RDFSをさらに拡張し、より複雑で厳密な関係性を定義するための言語で、これにより、AIがより高度な自動推論を行えるようになる
- 同値関係: [Nihon] は [Japan] と同じものである (owl:sameAs)
- 排反関係: [男性] と [女性] は同時には成り立たない (owl:disjointWith)
- 数量の制約: [人間] は [親] をちょうど2人持つ (owl:cardinality)
これらの記述を組み合わせることで、単なるデータの集まりではなく、コンピュータは体系化された「知識」として情報を扱い、人間のように推論することが可能になる。

### 2-2-6. 概念間の関係（is-aとpart-ofの関係）
is-aの関係は推移律が成立する（[犬] --(is-a)--> [動物]、[動物] --(is-a)--> [哺乳類]）
part-ofの関係は推移律が成立するとは限らない（[肉球] --(part-of)--> [足]、[足] --(part-of)--> [人体]）

part-ofはいろいろある。
1. 構成要素 - オブジェクト (Component - Integral Object) 機能を持つ部品が、全体を構成する関係
  [車輪] --(part-of)--> [自転車]：自転車は車輪がないと自転車ではない/車輪は車輪のまま
2. メンバー - 集合 (Member - Collection)個々のメンバーが、特定の集団やグループを構成する関係
  [木] --(part-of)--> [森]：森は木が1本減っても森/木は木のまま
3. 部分 - 量 (Portion - Mass)明確な境界を持たない「かたまり」から、その一部分を切り出す関係
  [一杯の水] --(part-of)--> [プールの水]
4. 素材 - オブジェクト (Stuff - Object) 物が「何でできているか」という材質を示す関係
  [鉄] --(part-of)--> [フライパン]
5. 特徴 - 活動 (Feature - Activity) より大きなイベントやプロセスの中に含まれる、個々の段階や特徴を表す関係
  [支払] --(part-of)--> [買い物]
6. 場所 - エリア (Place - Area) ある場所が、より広い地理的な範囲に含まれる関係
  [東京] --(part-of)--> [日本]
人間は意識せずにこれらの概念を使うけど、コンピュータにこれを理解させるのはかなり難しいよね。

### 2-2-7. オントロジーの構築
オントロジーの研究が進み、知識を記述することの難しさがわかってくると、2大潮流が生まれる。
- ヘビーウェイト・オントロジー（重量オントロジー）：対象世界の知識をどのように記述すべきかを哲学的にしっかり考えて行う
- ライトウェイト・オントロジー（軽量オントロジー）：効率を重視し、とにかくコンピュータにデータを読み込みできる限り自動的に行う

ヘビーはどうしても哲学的な考察が必要となるので人間が関わる傾向が強く、時間とコストがかかる（Cycプロジェクトとかね）
ライトは完璧を求めず、コンピュータで概念間の関係性を自動で見つけよう（ウェブマイニングやデータマイニングとかね）

## 2-3. 機械学習・深層学習
機械学習、ニューラルネットワーク、深層学習の歴史とそれぞれの関係について

### 2-3-1-1. データの増加と機械学習
データの特徴が増えると適切な学習を行うために必要なデータ量が著しく増加する。（次元の呪い）
データの次元（データ空間の広さ）に見合ったデータ量がないと、データが不足している部分の学習が困難になる（汎化性能が落ちる）ために起きる現象。多くの特徴をもつデータを機械学習で扱うには、次元（特徴量）を減らす工夫や、多様かつ質の高いデータを大量に用意しなればならない。

空間がどれだけ急速に広くなるかを考えると、、、
- 1次元（線）: 10mの直線の上で、1mごとにデータ点を置くと10個で済みます。
- 2次元（面）: 10m x 10mの正方形の床を1m²ごとに埋めるには、100個のデータ点が必要です。
- 3次元（立体）: 10m x 10m x 10mの立方体の部屋を1m³ごとに埋めるには、1000個のデータ点が必要です。

このように、次元（特徴量）が1つ増えるたびに、空間を同じ密度でカバーするために必要なデータ量は指数関数的に (exponentially) 増加することが直感的にわかるね。
少ないデータ量だと、高次元の空間が空っぽの状態になる。モデルは、手元にあるまばらなデータにだけ過剰に適合してしまい、未知のデータ（空間の空っぽの部分）に対しては全く役に立たない予測をしてしまう。（汎化性能の低下）
「次元の呪い」は、特に画像認識や遺伝子情報解析など、特徴量が数千〜数百万に達する分野で深刻な問題となり、これをいかに回避するかがモデルの性能を左右する鍵となる。

2000年代に入って本格的に登場したビッグデータは、まさしく「次元の呪い」を緩和するための**「データの増強」を可能にした**
**ビッグデータが「データの増強」を可能にした理由**
- インターネットの爆発的な普及：Webサイトの閲覧履歴など人々の活動がデジタルデータとして大量に生成・蓄積、利用可能データの絶対量が飛躍的に増加
- ストレージコストの劇的な低下：企業や研究機関がテラバイト級、ペタバイト級のデータを低コストで保存できるようになった
- 分散処理技術の発展：一台のコンピュータでは処理しきれない巨大なデータを、多数のコンピュータに分散させて並列処理する技術（Hadoopなど）が登場

2000年代以降のビッグデータの台頭は、それまで理論上は可能でもデータ量の制約で困難だった機械学習モデル（特に後の深層学習）の実用化を後押しし、「次元の呪い」に対する強力な解決策の一つとなったよ。

**機械学習の変遷と各技術の位置づけ**
基礎技術 → 高性能技術 → ビッグデータという環境変化 → 現在の主流技術
1. 1960s-1980s：基礎アルゴリズムの時代
この時期に、現在の機械学習の元となる多くの基本的なアルゴリズムが考案される
- k-means法： 1960年代に基本的な考え方が確立された、古典的なクラスタリング手法です
- 遺伝的アルゴリズム： 1970年代に体系化された、生物の進化を模倣した最適化手法です
2. 1990s： 高性能アルゴリズムの時代
より複雑な問題に対応できる、高性能なアルゴリズムが人気を博す
- サポートベクターマシン (SVM)： 1990年代に大きな注目を集めた、非常に強力な分類アルゴリズムです。一時期は、最も優れた手法の一つと見なされていました。
3. 2000s以降: ビッグデータと深層学習の時代
インターネットの普及により、状況が大きく変わる
- Google検索エンジン：機械学習の「アルゴリズム」そのものではないけど、の登場は2つの点で重要だった
- 1. Webというビッグデータを生み出す巨大なプラットフォームとなった
- 2. その膨大なデータを整理・活用するために、機械学習技術を大々的に利用する応用例となった
- ビッグデータを利用した機械学習: 2000年代以降の主流です。大量のデータとコンピュータの計算能力の向上を背景に、それまで理論上は強力でも実用的でなかったニューラルネットワークが復活し、**深層学習（ディープラーニング）**として大きな成功を収めた。

### 2-3-1-2. 機械学習と統計的自然言語処理
統計的自然言語処理を使った機械翻訳（SMT）では、従来のルールベース機械翻訳（RBMT）のように文法構造や意味構造を分析して、単語単位で訳を割り当てるのではなく、複数の単語をひとまとまりにした単位（句、または文単位）で用意された膨大な量の原文と訳文のペア（対訳コーパス）を読み込ませ、統計的に「こういう原文のときは、こういう訳文になる確率が高い」というパターンを自動で学習させる。

この統計的機械翻訳（SMT）がさらに発展し、現在主流となっているのがニューラルネットワークを用いた**ニューラル機械翻訳（NMT）**だよ。

### 2-3-1-3. 特徴量設計（Garbage In, Garbage Out）
機械学習では、「注目すべきデータの特徴」の選び方が性能を決定づける。効果的な特徴量を見つけ出す作業（特徴量エンジニアリング）は、機械学習プロジェクト全体の中で最も時間がかかり、そして最も専門性が問われる部分の一つ。なぜなら、
- 専門知識（ドメイン知識）が必要
- 試行錯誤の繰り返し
- 隠れた関係性の発見
- データの品質問題

手作業による特徴量エンジニアリングの難しさを解決するために登場したのが、**特徴表現学習（Representation Learning）**だよ。
**特徴表現学習とは**、機械学習モデルがデータから直接、自動的に有効な特徴量を学習手法。人間が「これっぽいな」と教えるのではなく、モデル自身がデータに潜む本質的なパターンや構造を発見する。このアプローチが特に得意なのが、**深層学習**

特徴表現学習のメリットは、自動化と性能向上。特徴表現学習は、機械学習の性能を向上させ、応用範囲を大きく広げるための鍵になる技術だよ。

### 2-3-2-1. ニューラルネットワーク
ニューラルネットワークは、人間の脳にある神経細胞（ニューロン）のつながりを、数式モデルで模倣したものです。データの中に隠れた複雑なパターンを見つけ出すことを得意としており、現在のAIや深層学習（ディープラーニング）の中核をなす技術。
ニューラルネットワークは、主に3種類の**層（Layer）**で構成されている。
1. 入力層 (Input Layer)：
2. 中間層 (Hidden Layer)：ここで実質的な計算が行われ、入力された情報から、より複雑で抽象的な特徴を捉える。この中間層が多層に積み重なったものが「ディープラーニング」と呼ばれる。
3. 出力層 (Output Layer)：

どうやって学習するのか？
ニューラルネットワークは、大量の学習データ（問題と正解のセット）を使って学習する
- まず、学習データを使って予測を試みる
- その予測と、あらかじめ用意された「正解」を比べ、どれくらい間違っていたか（誤差）を計算する
- その誤差がより小さくなるように、ニューロン間の結合の強さを少しずつ調整する
- このプロセスを何百万回、何億回と繰り返すことで、ネットワークは次第に賢くなり、未知のデータに対しても高い精度で答えを導き出せるようになる

学習可能なニューロンモデルの元祖は"パーセプトロン"
1950年代に考案された、最も初期のシンプルなニューラルネットワークです。現在のAIに使われている人工ニューロンの原型とも言える存在です。

基本的な仕組み
パーセプトロンは、複数の入力情報を受け取り、それに基づいて「はい (1)」か「いいえ (0)」のどちらか一方を出力する、単純な決定モデルです。
- 複数の入力データを受け取ります。
- 各入力には、その重要度を示す重みが付いています。
- 入力と重みを掛け合わせた値の合計を計算します。
- その合計が、あらかじめ決められたしきい値を超えたら「1」を、超えなければ「0」を出力します。
- この仕組みにより、2つのグループに分けられるデータ（例えば、スパムメールか否か）を分類することができます。

歴史と限界
パーセプトロンは、AIの初期の研究を大きく前進させましたが、一つの大きな限界がありました。それは、一本の直線で分けられるような単純な問題（線形分離可能な問題）しか解けないことです。

この限界により、一時的にニューラルネットワーク研究は下火になりました。しかし、後にパーセプトロンを複数組み合わせ、層状に重ねる「多層パーセプトロン」へと発展することで、この限界を克服し、現在の複雑なニューラルネットワークや深層学習への道を開くことになりました。

### 2-3-2-2. 深層学習
多層化したニューラルネットワークを使って、データに潜む特徴を自動的に学習する手法が深層学習。誤差逆伝播法（バックプロパゲーション）という手法が提唱されるまで、多層化したニューラルネットワーク全体ではなく、最後の層のニューロンだけを学習させることが限界だったよ。
誤差逆伝播法（バックプロパゲーション）は、ニューラルネットワークを訓練（学習）させるための中心的なアルゴリズムです。
ネットワークが出した予測の「間違い（誤差）」が、ネットワーク内のどの部分の責任だったのかを効率的に計算し、賢く修正していくための手法です。

なぜ必要なのか
ニューラルネットワークは、学習データを使って予測を行い、その結果と「正解」を比べることで、自身の内部パラメータ（重み）を少しずつ調整し、賢くなっていきます。
この時、ネットワークのどの部分を、どのくらい修正すれば間違いが減るのかを特定する必要があります。誤差逆伝播法は、この「責任の押し付け合い」を効率的に行うための計算方法です。

簡単な流れ ↩️
1. 順伝播（予測）: まず、ネットワークにデータを入力し、普通に予測をさせます。
2. 誤差の計算: 出てきた予測と、本来の「正解」を比べて、どれだけ間違っていたか（誤差）を計算します。
3. 逆伝播（誤差の伝達）: 計算した誤差を、出力層から入力層へ逆向きに伝えていきます。この過程で、各ニューロンの結合（重み）が、最終的な誤差にどれだけ貢献したかを計算します。
4. 重みの更新: 誤差への貢献度に応じて、各結合の重みを「誤差がより小さくなる方向」に少しだけ調整します。

この1〜4のサイクルを何万回、何百万回と繰り返すことで、ニューラルネットワークはデータに潜むパターンを学習し、非常に高い精度で予測ができるようになります。この手法の発見が、今日の深層学習（ディープラーニング）の発展を可能にしました。

### 2-3-2-4. 自然な文章を生成できる「大規模言語モデル」の登場
統計的自然言語処理や、従来のニューラルネットワークでは単語の意味を大きな文脈のなかで把握することが困難で、学習にすごく時間がかかっていた。他の単語との関係性を把握するのって大変。
Transformerは、文章中の単語の位置を考慮し、単語と単語の関係性（アテンション（注意力））を広範囲にわたって学習。
さまざまな文脈や状況で使われる単語の意味やニュアンスを深く理解（してる風）だけでなく、文中の任意の単語間の関係性を複数同時に効率よく計算できるようになった。
大量の言語データを学習する能力を持つ、大規模なニューラルネットワークを「大規模言語モデルLLM」というよ。
与えられた大量の文章を学習することで、一般的な言語の構造、文法、語彙などの基本を学ぶ = 事前学習
事前学習だけでは、学習した文章を単純に再現するだけになってしまい、論理的な回答を生成したり、不適切な発言を避けたりすることを学んでいないので、望ましい状態ではない。そこで、ファインチューニング（微調整）と呼ばれる学習を追加して、特定のタスクや応用分野に焦点を当てた訓練を行い、文脈を理解して論理的かつ適切な回答を生成する能力を向上させる。

<!-- tag: 人工知能をめぐる動向・章2 -->
**【復習ポイント】第2章：人工知能をめぐる動向**

#### **探索・推論（第1次AIブーム）**
問題を「探索木」と呼ばれるデータ構造に変換し、最適な答えを見つけ出す手法。

**代表的な探索アルゴリズム**
| アルゴリズム | 特徴 | 用途 |
| :--- | :--- | :--- |
| **深さ優先探索（DFS）** | とにかく深く探索し、行き止まりで戻る。実装が容易。 | 最短経路が不要で、素早く一つの解を見つけたい場合。 |
| **幅優先探索（BFS）** | スタートから近い順に網羅的に探索。 | 最短経路・最小手数を確実に見つけたい場合。 |
| **A\*アルゴリズム** | 実コストと推定コスト（ヒューリスティック）を基に探索。 | DFSとBFSの長所を両立。カーナビなどで利用。 |

**主要な問題とアプローチ**
* **ハノイの塔**: 「再帰」を用いて、大きな問題を小さな同じ問題に分解して解く。
* **ロボットの行動計画**: STRIPSやPDDLといった記述形式で、「初期状態」「ゴール状態」「行動の定義」を基に計画を立てる。
* **ボードゲーム**:
    * **課題**: 組み合わせ爆発により全探索は不可能。
    * **Mini-Max法**: 自身はスコアを最大化し、相手は最小化すると仮定して先読みする。
    * **αβ法**: Mini-Max法を効率化。明らかに無駄な手を「枝刈り」して計算量を削減する。
    * **モンテカルロ法**: 局面の評価が困難な囲碁などで有効。ランダムなシミュレーション（プレイアウト）を多数行い、勝率の高い手を選ぶ。
    * **AlphaGo**: 深層学習とモンテカルロ木探索を融合。
        * **ポリシーネットワーク**: 人間の「直感」のように有望な手を絞り込む。
        * **バリューネットワーク**: 「形勢判断」のように局面の有利不利を評価する。

#### **知識表現（第2次AIブーム）**
人間が持つ知識をコンピュータが扱える形式で表現し、推論に利用する手法。

**主要な概念と技術**
| 概念/技術 | 説明 | 例 |
| :--- | :--- | :--- |
| **人工無能** | パターンマッチングで人間と対話しているように見せかけるプログラム。内容は理解していない。 | イライザ（ELIZA） |
| **エキスパートシステム** | 専門家の知識をルールとして蓄積し、専門家のように振る舞う。 | マイシン（MYCIN） |
| **知識獲得のボトルネック** | エキスパートシステムの限界。専門家の暗黙知の獲得や、知識ベースの保守が困難。 | - |
| **意味ネットワーク** | 概念をノード、関係をリンクで表現したグラフ。`is-a`（継承）や`part-of`（部分）関係が基本。 | [犬] --(is-a)--> [動物] |
| **オントロジー** | 知識の共有・再利用のため、概念体系を明確に定義する方法論。 | Cycプロジェクト |

**オントロジー記述言語**
| 言語 | 役割 | 機能 |
| :--- | :--- | :--- |
| **RDF** | 基本骨格 | 全ての情報を「主語-述語-目的語」の3つ組で表現。 |
| **RDFS** | 階層定義 | RDFの語彙（クラス等）を定義し、基本的な階層関係を記述。 |
| **OWL** | 複雑な関係定義 | RDFSを拡張し、同値・排反関係など厳密な定義を可能にし、高度な自動推論を実現。 |


#### **機械学習・深層学習（第3次AIブーム以降）**
データからパターンやルールを自動で学習する手法。

**主要な概念と技術**
* **次元の呪い**: データの特徴量（次元）が増えるほど、性能維持に必要なデータ量が指数関数的に増加する問題。ビッグデータの登場がこれを緩和した。
* **特徴量設計**: モデルの性能を左右する重要なプロセス。「Garbage In, Garbage Out（ゴミを入れたらゴミが出る）」が原則。
* **特徴表現学習**: モデル自身がデータから有効な特徴量を自動で学習する手法。深層学習が得意とする。
* **ニューラルネットワーク**:
    * 人間の脳神経を模倣した数式モデル。入力層・中間層・出力層で構成。
    * **パーセプトロン**: 初期ニューロンモデル。線形分離可能な問題しか解けず、研究停滞の一因となった。
* **深層学習**:
    * 中間層を多層に重ねたニューラルネットワーク。
    * **誤差逆伝播法（バックプロパゲーション）**: 多層ネットワークの学習を可能にした中心的アルゴリズム。出力の誤差を逆向きに伝え、ネットワーク全体の重みを効率的に調整する。
* **大規模言語モデル（LLM）**:
    * **Transformer**: 「アテンション」機構により、文章中の単語間の広範な関係性を効率的に学習するアーキテクチャ。
    * **事前学習**: 大量のテキストデータで言語の基本構造を学ぶ。
    * **ファインチューニング**: 事前学習済みモデルを特定のタスクや目的に合わせて微調整する。


## 3. 機械学習の具体的手法
### 3-1. 具体的手法
機械学習で扱う問題の種類、各問題における代表的な手法について。

#### 3-1-1. 学習の種類
個別の課題は千差万別だけど、解決手段は3つに分類できる。

### 3-1-2. 代表的な手法（教師あり学習）
与えられた入力データを元に、そのデータがどんな出力パターンになるのかを、識別・予測する。入力と出力がセットになってる。
- 過去の売り上げから未来の売り上げを予測する（予測したものが数値 = 連続する値 = 回帰問題）
- 与えられた画像が何の動物かを予測する（予測したいものがカテゴリ = 連続しない値 = 分類問題）
- 与えられた英文を和訳する

#### 3-1-2-1. 線形回帰
統計でも用いられる手法で最もシンプルなモデル。
データが直線的な関係を持つと仮定し、その関係を表す一本の直線を引くことで、未知の数値を予測するよ。
- 結果が単純な直線だから、なぜこの予測結果になったのか？が理解しやすい。
- 数値の予測（回帰）で使われる。連続する数値を予測する回帰問題で使われる。
- 入力に重みをかけて合計するという考え方はニューラルネットワークなどより高度なモデルの基本にもなってる。（線形回帰に正則化項を加えた手法としてラッソ回帰、リッジ回帰がある）

1つの入力データから出力を予測する回帰分析を単回帰分析、複数種類の入力を用いる場合を重回帰分析。


ちなみに、モデルモデルって言い回しが多いけど、これは**階層1：モデルの「設計図・種類」としてのモデル**。まだ学習もされていない、手法そのものを指すよ。モデル構造（アーキテクチャ）
線形回帰などのモデルにデータを入れて学習させた結果を具体的な成果物を、**階層2：学習済みの「成果物」としてのモデル**、特定のパラメータ（線形回帰なら、具体的な傾きや切片の値）を持った、世界に一つだけの**インスタンス（実体）**。（学習済みモデル）このモデルの精度は95％だった、学習済みのモデルを保存する、とかね。
より広く、**「どのようなアプローチで問題解決に取り組むか」という"考え方"や"枠組み"**を指す、最も抽象的な使い方が、**階層3：問題解決の「枠組み」としてのモデル**、これは教師あり学習モデルだね、あの子が強化学習のモデルを採用してる、とか。

作るプロセスで捉えると、
- まず、やりたいことを観察する
- それに適したアプローチを決定する（階層3を決める）
- 次に手法を選択する（階層1を選ぶ）
- 最後にデータで学習させて具体的な成果物をつくる（階層2）
どこの話をしているのか？で考えると多義的に用いられるモデルという単語がどの意味か明確になるよ。がんばろ！


#### 3-1-2-2. ロジスティック回帰
分類問題に用いる手法をロジスティック回帰（名前に回帰ってつくけどね）
シグモイド関数を用いて、モデルを出力します。（この場合もモデルは階層2）
任意の値を0から1の間に写像するシグモイド関数を用いることで、与えられた値が正例（+1）になるか、負例（0）になるかの確率が求まる。出力の値が0.5以上なら正例、0.5未満なら負例と設定しておくことでデータを2種類に分類できるよ。2クラス分類問題。
基本的には閾値は0.5だけど、0.7や0.3にしたり、分類の調整可能

2種類以上の分類を行いたい場合、シグモイド関数の変わりにソフトマックス関数を用いることになる。多クラス分類問題。

#### 3-1-2-3. ランダムフォレスト
決定木を用いる手法。
教師あり学習は、複数の特徴量をもとに予測結果を出力するので、どの特徴量がどんな値になっているかを順々に考えて、それに基づいて分岐路（決定木）を作っていけば、最終的に1つのパターンが予測できるはず。
ランダムに一部データを取り出して（ブートストラップサンプリング）、決定木を複数作成する。複数の決定木を作成するので、結果もそれぞれの決定木で異なるので、多数決するよ。
ランダムフォレストというモデル（階層1のモデル）の中で、複数のモデル（これも階層1のモデル）を学習させることをアンサンブル学習という。また、全体から一部のデータを用いて複数のモデルを用いて学習する方法をバギングというよ。バギングは並列。

#### 3-1-2-4. ブースティング
バギング同様、複数のモデルを学習させるので、これもアンサンブル学習。ブースティングは直列で、逐次的にモデルを作成する。
間違えやすい部分を重点的に学習するというプロセスを繰り返すってこと。チーム全体として精度の高いモデルを構築する。
得られる精度はバギングよりも高いけど、時間もかかる。

#### 3-1-2-5. サポートベクターマシン（SVM）
深層学習以前にもっとも人気のあった手法のひとつ。異なるクラスの各データ点との距離が最大（マージン最大化）となるような境界線を求めることで、パターン分類を行う。
- 扱うデータは高次元
- データが直線分類できない（直線で分類できない）

赤と青の点が混ざり合ってプロットされているとき、その配置だと1本の直線で赤と青を分けられない。
その時、赤を浮かせると横から見て赤と青を分けれれる = **データを高次元に写像して、分離しやすくする** = カーネルトリック

#### 3-1-2-6. 自己回帰モデル
時系列データを対象とした回帰問題に適用される手法。
株価日足推移、世界人口の年毎の推移、ネット通信のパケット通信量の推移など。時系列分析は、過去のデータとの関係性を何かしらモデル化すればいいらしい。過去のデータは1種類でも複数種類でもOK。複数種類の場合はベクトルとなり、このときの自己回帰モデルをベクトル自己回帰モデル（VARモデル、vector autoregressive model）というよ。

### 3-1-3. 代表的な手法（教師なし学習）
入力そのものが持つ特徴・構造が学習の対象。出力データはない。
- 売上データから、どういった顧客層があるのか確認したい
- 入力データの各項目間にある関係性を把握したい。

#### 3-1-3-1. 階層なしクラスタリング（k-means法）
データを指定した個数（k個）のグループ（クラスター）に自動で分ける、**「似ているもの同士を同じグループに集める」**という手法。予測や分類ではなく、データの中に隠れている構造を見つけ出すのが目的です。

- kの数を決める必要がある: 事前に「いくつのグループに分けたいか」人間が決める必要あり
- クラスタリングに使用: 顧客のセグメンテーションや、画像分割領域など、正解ラベルのないデータをグループ分けするときに利用
- １９６０年代いにしえのクラスタリング手法

#### 3-1-3-2. 階層ありクラスタリング
階層ありクラスタリングは、データのグループ分けを一度に行うのではなく、樹形図（デンドログラム）のような階層構造を作る手法。一番似ているデータ同士から徐々に大きなグループへとまとめていくことで、「AとBは似ているな。そのグループCと、Dはちょっと離れているな」といった、グループ間の関係性まで可視化することができるよ。
ウォード法、最短距離法など。
- 階層なし (k-meansなど): データを指定された数のグループに分割するだけ。
- 階層あり: グループ間の類似度や階層関係まで含めて分析する。

#### 3-1-3-3. 主成分分析
k-means法やウォード法はデータをクラスタに分類することでデータの構造を把握していたが、主成分分析（Principal Component Analysis PCA）はデータの特徴量間の関係性、つまり相関を分析することでデータの構造を把握する。

特に特徴量が多い場合に用いられ、相関を持つ多数の特徴量から、相関のない少数の特徴量へと次元削減することが目的。特徴量が少なることで、データの分析がしやすくなったり、教師あり学習の入力として用いる場合に計算量を減らせる。

**次元削減の手法**
- 特異値分解（Singular Value Decomposition SVD）: 文章データを扱う場合に使用されがち
- 多次元尺度構成法（Multi-Dimensional Scaling MDS）: 2次元への次元削減、可視化
- t-SNE（t-distributed Stochastic Embedding）: 2次元・3次元

#### 3-1-3-4. 協調フィルタリング
レコメンドシステムで用いられる。ECサイトなどで、「対象ユーザーは買っていないが、類似ユーザーは買っている商品を推薦する」ような感じ。ただ、これは事前にある程度参考にできるデータがないと、推薦を行えない = **コールドスタート問題**
これに対し、ユーザではなく、商品に何かしらの特徴量を付与し、特徴が似ている商品を推薦する**コンテンツベースフィルタリング**、こちらは対象ユーザの情報さえあれば推薦を行えるので、コールドスタート問題は回避できるが、他のユーザーの情報を参照することができない。

#### 3-1-3-5. トピックモデル
K-means法やウォード法と同様、クラスタリングを行う手法。データをひとつのクラスタに分類するk-means法などとは異なり、トピックモデルは複数のクラスタにデータを分類するのが特徴。
- 潜在的ディリクレ配分法（Latent Dirichlet allocation LDA）

文書データを対象とした場合、各文書は「複数の潜在的トピックから確率的に生成される」と仮定したモデル。
ニュース記事を政治・経済・スポーツに分ける際、どの分野に分類されるかを記事内に出てくる単語からそれぞれ確率によって求める。
トピックモデルは文書間の類似度を求められるので、似たものを探す = 推薦する、つまりレコメンドシステムにも使える。

#### 3-1-4-1. 代表的な手法（強化学習）
強化学習は「試行錯誤を通じて最適な行動を学ぶ」という学習方法です。ゲームをプレイするように、エージェント（AI）が環境とやり取りしながら、報酬を最大化するように行動を改善していくよ。（強化学習における「エージェント」は、環境と相互作用しながら行動を選び、報酬を得て学習する存在のことです。つまり、AIの一種ではあるけれど、特定の役割や枠組みの中で定義された存在だよ）

行動を学習する仕組み。明確な正解を教えられるのではなく、行動の結果得られる報酬を最大化するように自らの最適な戦略を見つけ出していくのが強化学習の特徴。
- 最初から正解は知らない。何度も試行錯誤しながら学ぶ
- 今の行動がすぐじゃなくて、将来の報酬につながることもある。
- 正解データが不要。教師ありとはちがって、この状況ではこの行動が正解というデータが不要。報酬（スコア）というヒントが与えられる。

目的は、将来にわたって獲得できる累積報酬の最大化すること。強化学習における**割引率（Discount Factor）**は、将来の報酬をどれだけ重視するかを決めるとても重要なパラメータ。今の100円と1年後の100円だったら、今の100円の方が価値がある。

#### 3-1-4-2. バンディットアルゴリズム
強化学習では累積報酬が最大になるような行動を求める必要があるけど、一連の行動の組み合わせはほぼ無限にあるので、どこまで行動の選択肢を考えるべきかが大きな課題。そこで用いられる考え方が、**活用（exploitation）と探索（exploration）**。
- 活用: 現在知っている情報の中から報酬が最大となるような行動を選ぶ。
- 探索: 現在知っている情報以外の情報を獲得するために行動を選ぶ。

ある程度試行錯誤したら、報酬が高かった行動を積極的に選択するのが活用、もっと他に報酬が高い行動があるのではと別の行動を選択するのが探索。
この二つはトレードオフの関係だから、バランスをとるのがポイント。

そこで！バンディットアルゴリズムです。
- ε-Greedy方策（epsilon-Greedy policy）: 一定の確率 ε で探索、探索しない場合は最良の選択肢を活用。探索しないこともあるよ。
- UCB（Upper-Confidence Bound policy）: 報酬の期待値と、試行回数が少ない行動ほど不確実性が高いとみなし、優先的に選択。楽観的だね。
- Thompson Sampling: ベイズ推定を使って確率的に選択肢を評価
policyは「ある状態からとりうる行動の選択肢、およびその選択肢をどう決定するかの戦略」を指し、各行動を選択する確率表現だよ。

#### 3-1-4-3. マルコフ決定過程（MDP）モデル
マルコフ性（Markov Property）は強化学習の基本的な前提のひとつです。特に、**マルコフ決定過程（MDP: Markov Decision Process）**という枠組みが、強化学習の理論的基盤になっています。
マルコフ性とは、**現在の状態と現在の行動にのみ依存し、それより以前の状態や行動には依存しない。そして、現在の状態がすべての未来に関する情報を含んでいる**という性質。

現在の状態がすべての未来に関する情報を含んでいる、これはつまり「未来を予測するのに、過去の情報はもういらない」、今の状態が過去の履歴をすべて表していて、未来の挙動を決めるのに十分ってこと！

強化学習では、エージェントが「今の状態」をみて、「次に何をするか」を決める。決めるとき、過去の履歴を全部覚えておかないといけないとしたら、学習が超ハードモード。

#### 3-1-4-4. 価値観数
強化学習の目的は、報酬最大化だけど、実際は最適な方策を見つけ出すのはとても困難なことが多い。そこで、最適な方策を直接求める代わりに、状態や行動の「価値」を設定し、その価値が最大となるように学習するアプローチ。
状態や行動の価値を学習すれば、価値が高い行動を選ぶことで、結果的に報酬が最大化されるてこと！

学習の流れ
- 状態や行動に対する価値関数（VやQ）を推定
- 推定された価値をもとに、より良い方策を選択・改善
- 改善された方策で再び価値関数を更新
- この繰り返しで、最適方策に近づいていく

強化学習では、エージェントが環境と相互作用しながら、報酬を最大化するような行動方針を学習する。その過程で「価値関数」が重要な役割を果たすよ。なぜなら、
- エージェントは「どの状態がいいか」「どの行動がいいか」を判断するための基準になる
- 最適なポリシー（行動方針）を導くために使われる
- Q学習やSARSAなどのアルゴリズムでは、行動価値関数を直接更新して学習する
つまり、方策を見つけるための道しるべたね。

環境と相互座用の流れは、
1. 状態の観察（現在地の把握など）
2. 行動の選択（右に進むなどの行動）
3. 環境の変化（行動の結果、状態が変化する）
4. 報酬の受け取り（ゴールしたら+100など）
5. 学習 （次へ）

- 状態価値関数（State Value Function）★: ある状態にいることの価値を数値で表現（その状態から開始して、ある方策に従って行動したときに、将来的に得られる報酬の期待値
- 行動価値関数（Action Value Function）★★★: エージェントがある状態で特定の行動をとったとき、将来的に得られる報酬の期待値を表現

たんに価値関数という場合、行動価値関数を指す。

#### 3-1-4-5. 方策勾配
強化学習において、方策を直接最適化する手法。価値関数を使わず、報酬を最大化するように方策のパラメータを勾配法で更新するんだよ。

- REINFORCE: モンテカルロ法で報酬を推定し、方策の勾配を更新
- Actor-Critic: 方策（Actor）と価値関数（Critic）を同時に学習
- PPO（Proximal Policy Optimization）: 安定性と効率性を両立した人気手法

方策勾配法はロボット制御など、特に行動の選択肢が大量な課題で用いられる。行動の選択肢ごとに価値を算出すると計算コストが莫大になってしまい、学習できないかもしれないから。

### 3-2. モデルの選択・評価
機械学習のモデルを評価するためにはどのような処理が必要なのか？
評価において、データをどのように扱うか、どのように評価するかが重要。

#### 3-2-1. データの扱い
機械学習の手法がたくさんあるけど、それぞれの手法で得られるモデルを仕様する際は、そのモデルがどれくらいの予測性能を持っているのかを評価する必要がある。どのように評価するのかはとでも重要。

（ここでいう「モデル」は成果物としての階層2のモデル）

機械学習の目的は、手元にあるデータを学習することでデータの特徴をつかみ、未知のデータを与えられたときにそれがどういった出力になるのかを正しく予測すること。未知のデータに対しての予測能力をを評価するには問題がある。未知のデータなので、データを準備することができない。そのため、手元にあるデータから疑似的に未知のデータを作り出すことになる。つまり、手元にある全データを学習データと評価データにランダムに分割して評価する。学習用のデータを**訓練データ**、評価用のデータを**テストデータ**と呼ぶ。
また、このようにデータを分割して評価することを**交差検証**というよ。

1. ホールドアウト検証: 機械学習モデルの性能を評価するための基本的な手法のひとつ（分割は1回、コストが低い、データ量が十分なら信頼性の高い評価が可能）
2. K-分割交差検証: データの分割を複数回行い、それぞれで学習・評価する（汎化性能の評価が安定、偏りを減らせる）

### 3-2-2. 評価指標
#### 3-2-2-1. 予測誤差
モデルの良しあしの評価は何を基準にすればいいのか？分類問題であれば、「あたり・はずれ」が明確だけど、回帰問題は数値そのものを予測するわけなので、「あたり・はずれ」で分けられない。

これを解決するもっともシンプルなアプローチは、予測誤差をそのまま評価に用いることだよ。
**平均二乗誤差（mean squared error, MSE）**

2つのモデルの性能を比較する場合、それぞれのモデルでテストデータの平均二乗誤差値を求め、誤差値が小さいほうがより予測性能が高いモデルという判断が可能になる。
他にも、**二乗平均平方根誤差**、**平均絶対値誤差**などもあるよ。

#### 3-2-2-2. 正解率・適合率・再現率・F値
分類問題においては、「あたり・はずれ」でモデルの性能評価ができるが、予測の「あたり・はずれ」といっても、どういうデータに対して予測が当たったのか、外れたのかで、意味合いが異なる。様々なケースを適切に評価できるように、分類門際においてはいくつかの評価指標が定義されている。

**混同行列（Confusion Matrix）**
以下は、2クラス分類（例：陽性 vs 陰性）の混同行列です：
|  | 予測：陽性 | 予測：陰性 | 
| 実際：陽性 | 真陽性 (TP) | 偽陰性 (FN) | 
| 実際：陰性 | 偽陽性 (FP) | 真陰性 (TN) | 

- 正解率: (TP + TN) / (TP + FP + TN + FN)　全体の中で正しく予測できた場合
- 適合率: TP / (TP + FP)　陽性と予測した中で、実際に陽性だった割合
- 再現率: TP / (TP + FN)　実際に陽性だった中で、正しく陽性と予測できた割合
- F値（F1スコア）: 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}　適合率と再現率の調和平均

強化学習において、「陽性 = 報酬が得られる行動」、「陰性 = 報酬が得られない行動」

全体の中で正しく予測できなかった割合」は、**不正解率（Error Rate）または誤分類率（Misclassification Rate）**と呼ばれ、正解率とは補数関係にあるよ。

**正解率と不正解率**
| 指標名 | 定義 | 意味 | 
| Accuracy（正解率） | (TP + TN) / 全体 | 正しく予測できた割合 | 
| Error Rate（不正解率） | (FP + FN) / 全体 | 誤って予測した割合 | 

では、陰性と予測した中で、実際に陰性だった割合は？（陰性版の適合率）
真陰性率（Negative Predictive Value NPV）陰性予測の正しさを測る指標だよ。

**適合率と再現率**
| 指標名 | 定義 | 意味 | 
| Precision | TP / (TP + FP) | 陽性予測の正しさ | 
| NPV | TN / (TN + FN) | 陰性予測の正しさ | 
| Recall | TP / (TP + FN) | 陰性予測の正しさを測る指標 |
| FDR | FP / (TP + FP) | 陽性予測の誤り率（Precisionの逆） | 

正解率を評価するとして、訓練データに対して正解率を高めることは重要です。正解率が上がらない = 学習できていない。
訓練データに対して仮に正解率が99%だったとしても、テストデータで50%という結果では、訓練データに対して高い正解率を出していても、**汎化性能（generalization ability）**が低ければ、モデルとしては不適切です。


このモデルは訓練データにのみ最適化されすぎている状態。機械学習の目的は、未知のデータ（テストデータや実運用データ）に対しても正しく予測できるような「一般的なパターン」を学ぶことでなので、訓練データにのみ通用するモデルは不適切。このような状態に陥ることを過学習もしくは、過剰適合（Overfitting）と呼ぶ。

⚠️ 過学習を招く典型的なやり方
1. モデルが複雑すぎる
- ニューラルネットワークの層が多すぎる
- 決定木が深すぎる
- パラメータ数が多すぎる
結果：訓練データの細かいノイズまで覚えてしまう

2. 訓練データが少ない
- データ量が少ないのに複雑なモデルを使う
- 偏ったデータしか含まれていない
結果：限られたデータにだけ適応し、一般化できない

3. 正則化を使っていない／弱すぎる
- L1/L2正則化を使っていない
- Dropoutなどの手法を使っていない
結果：モデルが自由に学習しすぎてしまう

4. 訓練データとテストデータの分離が不適切
- データの分割がランダムでなく、偏っている
- テストデータに訓練データが混ざっている（リーク）
結果：テスト時に本来の汎化性能が測れない

5. 評価指標が訓練データに偏っている
- 訓練データの正解率だけを見てモデルを選ぶ
- テストデータでの評価を軽視する
結果：訓練データに最適化されたモデルが選ばれる

6. 過剰な学習回数（エポック数）
- エポック数が多すぎて、訓練データに完全にフィットしてしまう
結果：訓練誤差は減るが、テスト誤差が増える（典型的な過学習）

🧪 実例：過学習の兆候
# 過学習の典型的な学習曲線
Epoch: 1 → Train Accuracy: 70%, Test Accuracy: 68%
Epoch: 10 → Train Accuracy: 95%, Test Accuracy: 80%
Epoch: 50 → Train Accuracy: 99%, Test Accuracy: 50% ← 過学習！

過学習を防ぐには？
- モデルの複雑さを制限する（例：浅い決定木、少ない層）
- 正則化を導入する（L1/L2、Dropoutなど）
- 十分なデータ量を確保する
- 交差検証で汎化性能を評価する
- 早期終了（Early Stopping）を使う

**汎化性能を高めるための工夫**
| 方法 | 内容 | 
| 交差検証（Cross Validation） | データを分割して複数回評価し、過学習を防ぐ | 
| 正則化（Regularization） | モデルの複雑さにペナルティを与えて過学習を抑える | 
| 特徴選択・次元削減 | 不要な特徴を除去して、ノイズの影響を減らす | 
| データ拡張・増加 | より多様な訓練データを用意して汎化力を高める | 
| アンサンブル学習 | 複数のモデルを組み合わせて安定した予測を得る | 

#### 3-2-2-3. ROC曲線とAUC
正解率などとはまったく異なる観点で、モデルの性能を評価するのがROC曲線とAUC。2値分類の問題でよく使われるよ。

ROC（Receiver Operating Characteristic）曲線は、分類モデルのしきい値（threshold）を変化させたときの性能の変化を視覚的に示すグラフ
だよ。
- X軸：False Positive Rate（FPR）＝誤って陽性と判定した割合
\text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}}
- Y軸：True Positive Rate（TPR）＝正しく陽性と判定した割合 **（=Recall）**
\text{TPR} = \frac{\text{TP}}{\text{TP} + \text{FN}}

**AUC（Area Under the Curve）**は、ROC曲線の下の面積を表します。
- 値の範囲：0.0 ～ 1.0
- 意味：モデルがランダムな陽性・陰性のペアを正しく識別する確率

AUCの解釈：
| AUC値 | 意味 | 
| 1.0 | 完璧な分類モデル | 
| 0.9〜1.0 | 非常に優秀 | 
| 0.8〜0.9 | 良好 | 
| 0.7〜0.8 | まあまあ | 
| 0.5〜0.7 | 微妙（ランダムに近い） | 
| 0.5以下 | 逆に分類している（完全に誤っている） | 

#### 3-2-2-3. モデルの選択と情報量
モデルを複雑にすればするほど複雑な表現ができる可能性はあるけど、表現しなくていいノイズ部分まで表現してしまうことがある。「ある事柄を説明するためには、必要以上に多くを仮定するべきではない」（オッカムの剃刀）
じゃあどれくらいモデルを複雑にすればいいのか？という問いに対するひとつの目安となるのが、統計分野でも用いられる**情報量基準**
- 赤池情報量基準: AIC,モデルの適合度とパラメータ数のバランスを評価
- ベイズ情報量基準: BIC,AICよりも複雑なモデルに厳しいペナルティを課す

<!-- tag: 機械学習の具体的手法 -->
**【復習ポイント】第3章：機械学習の具体的手法**
**学習の種類**
機械学習で解決したい課題は、主に以下の3種類に分類される。
1.  **教師あり学習**: 正解ラベル付きのデータで学習し、識別・予測を行う。
2.  **教師なし学習**: 正解ラベルのないデータから、その構造やパターンを発見する。
3.  **強化学習**: 試行錯誤を通じて、報酬を最大化する行動を学習する。


**代表的な手法（教師あり学習）**
正解付きのデータ（入力と出力のセット）を学習し、未知のデータに対する出力を予測する。
* **回帰問題**: 売上予測など、連続する**数値**を予測する。
* **分類問題**: 動物の写真の分類など、**カテゴリ**（離散値）を予測する。

| 手法 | 説明 | 分類/回帰 |
| :--- | :--- | :--- |
| **線形回帰** | データが直線的な関係を持つと仮定し、数値を予測する最もシンプルな手法。 | 回帰 |
| **ロジスティック回帰** | シグモイド関数を使い、確率を出力することでデータを2種類に分類する。 | 分類 |
| **ランダムフォレスト** | 複数の決定木を組み合わせ、多数決で予測するアンサンブル学習。バギングの一種。 | 両方 |
| **ブースティング** | 間違えた部分を重点的に学習するモデルを逐次的に作成するアンサンブル学習。 | 両方 |
| **サポートベクターマシン (SVM)** | クラス間の距離（マージン）が最大となる境界線を引くことで分類する。カーネルトリックで非線形データにも対応。 | 分類 |
| **自己回帰モデル** | 過去の自身のデータに基づき、将来の値を予測する。時系列データの分析に用いる。 | 回帰 |


**代表的な手法（教師なし学習）**
正解データなしで、データそのものの構造やパターンを学習する。

| 手法 | 説明 |
| :--- | :--- |
| **クラスタリング** | データを似たもの同士のグループ（クラスター）に分ける。**k-means法**（階層なし）や**ウォード法**（階層あり）がある。 |
| **主成分分析 (PCA)** | 多数の特徴量を、相関のない少数の主要な特徴量に要約する（次元削減）。 |
| **協調フィルタリング** | レコメンドシステムで利用。「自分と似たユーザー」の行動に基づき推薦する。コールドスタート問題がある。 |
| **トピックモデル** | 文書データから潜在的なトピックを発見する。各文書は複数のトピックから構成されると仮定する。 |


**代表的な手法（強化学習）**
エージェントが環境内で試行錯誤し、報酬を最大化するような「最適な行動方針」を学習する。
* **バンディットアルゴリズム**: 「活用（現在の最善手）」と「探索（未知の手の試行）」のバランスを取る戦略。
* **マルコフ決定過程 (MDP)**: 「未来の状態は、現在の状態と行動のみで決まる」というマルコフ性を前提とした理論的基盤。
* **価値関数**: ある状態や行動の「良さ」を数値化したもの。Q学習などで利用される。
* **方策勾配法**: 価値関数を介さず、方策（行動戦略）を直接最適化する手法。


**モデルの評価**
学習済みモデル（階層2）が未知のデータに対してどれだけ正しく予測できるか（**汎化性能**）を測る。
* **交差検証**: 手元のデータを訓練データとテストデータに分割し、未知のデータに対する性能を擬似的に評価する。
* **過学習**: 訓練データに過剰に適合し、テストデータに対する性能が低下する状態。モデルが複雑すぎる場合や、データが少ない場合に発生しやすい。

**評価指標（分類問題）**
| 指標 | 説明 |
| :--- | :--- |
| **混同行列** | 予測結果と実際の結果をTP/TN/FP/FNで整理した表。 |
| **正解率 (Accuracy)** | 全データのうち、正しく予測できた割合。 |
| **適合率 (Precision)** | 「陽性」と予測した中で、実際に陽性だった割合。 |
| **再現率 (Recall)** | 実際に陽性だった中で、正しく「陽性」と予測できた割合。 |
| **F値 (F1-Score)** | 適合率と再現率の調和平均。両者のバランスを評価する。 |
| **ROC曲線とAUC** | モデルの分類性能をしきい値によらず評価する指標。AUCが1に近いほど高性能。 |

**評価指標（回帰問題）**
| 指標 | 説明 |
| :--- | :--- |
| **平均二乗誤差 (MSE)** | 予測値と実際の値の差（予測誤差）の二乗の平均。小さいほど良い。 |







## 4. 機械学習の具体的手法
### 4-1. 具体的手法
機械学習で扱う問題の種類、各問題における代表的な手法について。

#### 4-1-1. 学習の種類

#### 4-1-2. 教師あり学習
#### 4-1-3. 教師なし学習
#### 4-1-4. 強化学習

### 4-2. モデルの選択・評価
#### 4-2-1. 学習の種類
#### 4-2-2. 学習の種類
#### 4-2-3. 学習の種類



<!-- tag: AWS認定 Machine Learning - Specialty (MLS-C01) 試験ガイド -->
**AWS認定 Machine Learning - Specialty (MLS-C01) 試験ガイド要約**
**1. 試験の概要**

* **目的**: ビジネス課題に対し、AWSを使って機械学習(ML)ソリューションを「設計・構築・デプロイ・最適化・保守」する能力を検証する試験です。
* **対象者**: AWSクラウドでMLワークロードの「開発・設計・実行経験が2年以上」ある個人を想定しています。
* **試験形式**:
    * **問題数**: 全65問（うち、採点対象は50問、採点されない問題が15問。
    * **問題タイプ**: 4つの選択肢から1つを選ぶ「多肢選択式」と、5つ以上の選択肢から2つ以上を選ぶ「複数回答」の2種類があります。
* **合格ライン**:
    * スコアは100～1,000点で報告され、**合格点は750点**です。
    * 各分野で合格点を取る必要はなく、総合点で合格ラインを越えればOKです。

**2. 出題範囲と配点**

4つのドメイン（分野）から出題され、特に**「ドメイン3: モデリング」**の配点が最も高くなっています。

* **ドメイン1: データエンジニアリング (20%)**
* **ドメイン2: 探索的データ分析 (24%)**
* **ドメイン3: モデリング (36%)**
* **ドメイン4: 機械学習の実装と運用 (20%)**

**3. 【重要】試験で問われること**

* **データエンジニアリング (ドメイン1)**
    * データソースの特定と、S3、EFSなどのストレージ選定。
    * Kinesis、AWS Glue、EMRなどを使ったデータ取り込みパイプラインの実装。
    * ETLやデータ変換処理の実装。
* **探索的データ分析 (ドメイン2)**
    * 欠損データや破損データの処理。
    * データの正規化、拡張、スケーリング。
    * 特徴エンジニアリング（ワンホットエンコーディング、次元削減など）の実行。
    * グラフ作成や、相関などの記述統計の解釈。
* **モデリング (ドメイン3)**
    * ビジネス課題を、分類、回帰、クラスタリングなどのML問題として定義する。
    * XGBoost、CNN、RNN、大規模言語モデル(LLM)など、問題に適したモデルの選択。
    * 勾配降下法や損失関数といったトレーニング手法の理解。
    * ハイパーパラメータ最適化（正規化、クロス検証など）の実行。
    * モデルの評価（過学習/未学習の検出、AUC-ROC、適合率、再現率などの指標の評価）。
* **実装と運用 (ドメイン4)**
    * CloudWatchでのログ監視や、Auto Scaling、複数AZ配置など、高可用性なソリューションの構築。
    * **カスタムモデルを構築すべきか、SageMakerの組み込みアルゴリズムやAmazon RekognitionのようなAIサービスを使うべきかの判断** 。
    * IAM、S3バケットポリシー、VPC、暗号化など、基本的なセキュリティの適用。
    * A/Bテストの実行や、モデルの再トレーニングなど、デプロイと運用。

**4. 学習のポイント（特にあなた向け）**

* **【朗報】数学について**: **「複雑な数学的証明と計算」は試験範囲外**です。求められるのは、各アルゴリズムがどのような数学的直感に基づいているかを表現できることです。トレーナーの指示通り、コンセプトの理解に集中しましょう。
* **SageMakerが中心**: 試験範囲のサービスリストを見ると、**Amazon SageMaker**が中心的な役割を果たしていることがわかります。SageMakerの学習は最優先事項です。
* **Bedrockも範囲内**: あなたが業務で触れている**Amazon Bedrock**も試験範囲に含まれています。これはアドバンテージになります。
* **SAAの知識が活きる**: S3、VPC、IAM、CloudTrail、CloudWatchといったSAAで学んだコアサービスは、MLS試験でも当然のように問われます。復習が重要です。